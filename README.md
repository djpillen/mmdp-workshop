Structured Data Wrangling
=========================

[Mid-Michigan Digital Practitioners Meeting](http://archives.msu.edu/about/conferences.php?about_conferences)  
October 9, 2014

![Throwing the lasso.](http://images.nypl.org/index.php?id=1192646&t=w)

Whether you're a historical society managing Past Perfect catalog records, an academic library doing visualizations on subject relationships in MARC records, or an archive trying to reconcile years of legacy descriptive practices in EAD, chances are that you have some structured data or metadata sitting around somewhere, and it's messy!

Whether you call it data cleaning, data munging, data wrangling or something else, we'll show you the tools and techniques we're using to do it: OpenRefine and Python!

At the completion of this workshop, attendees will be able to:
  1. use Python to iterate through a directory of XML files and output the contents and location (XPath) of a particular node to a CSV file;
  2. use OpenRefine and the Google Refine Expression Language (GREL) to clean that CSV file; and
  3. use Python to update the original files with the cleaned nodes.
  
We'll just be covering the basics, but we hope this workshop will help to open your eyes to new and automated possibilities for cleaning data back at your institution!